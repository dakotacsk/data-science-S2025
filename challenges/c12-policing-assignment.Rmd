---
title: "Massachusetts Highway Stops"
author: "Dakota Chang"
date: 2025-04-25
output:
  github_document:
    toc: true
---

*Purpose*: In this last challenge we'll focus on using logistic regression to study a large, complicated dataset. Interpreting the results of a model can be challenging---both in terms of the statistics and the real-world reasoning---so we'll get some practice in this challenge.

<!-- include-rubric -->

# Grading Rubric

<!-- -------------------------------------------------- -->

Unlike exercises, **challenges will be graded**. The following rubrics define how you will be graded, both on an individual and team basis.

## Individual

<!-- ------------------------- -->

| Category | Needs Improvement | Satisfactory |
|-------------------|-----------------------------|-------------------------|
| Effort | Some task **q**'s left unattempted | All task **q**'s attempted |
| Observed | Did not document observations, or observations incorrect | Documented correct observations based on analysis |
| Supported | Some observations not clearly supported by analysis | All observations clearly supported by analysis (table, graph, etc.) |
| Assessed | Observations include claims not supported by the data, or reflect a level of certainty not warranted by the data | Observations are appropriately qualified by the quality & relevance of the data and (in)conclusiveness of the support |
| Specified | Uses the phrase "more data are necessary" without clarification | Any statement that "more data are necessary" specifies which *specific* data are needed to answer what *specific* question |
| Code Styled | Violations of the [style guide](https://style.tidyverse.org/) hinder readability | Code sufficiently close to the [style guide](https://style.tidyverse.org/) |

## Submission

<!-- ------------------------- -->

Make sure to commit both the challenge report (`report.md` file) and supporting files (`report_files/` folder) when you are done! Then submit a link to Canvas. **Your Challenge submission is not complete without all files uploaded to GitHub.**

*Background*: We'll study data from the [Stanford Open Policing Project](https://openpolicing.stanford.edu/data/), specifically their dataset on Massachusetts State Patrol police stops.

```{r setup}
library(tidyverse)
library(broom)
```

# Setup

<!-- -------------------------------------------------- -->

### **q1** Go to the [Stanford Open Policing Project](https://openpolicing.stanford.edu/data/) page and download the Massachusetts State Police records in `Rds` format. Move the data to your `data` folder and match the `filename` to load the data.

*Note*: An `Rds` file is an R-specific file format. The function `readRDS` will read these files.

```{r q1-task}
## TODO: Download the data, move to your data folder, and load it
filename <- '/Users/dakotachang/Desktop/school/2425Spring/DataScience/data-science-S2025/challenges/data/yg821jf8611_ma_statewide_2020_04_01.rds'
df_data <- readRDS(filename)
```

# EDA

<!-- -------------------------------------------------- -->

### **q2** Do your "first checks" on the dataset. What are the basic facts about this dataset?

```{r}
df_data %>% glimpse()

df_data %>% summary()

df_data %>% sapply(n_distinct)

sapply(df_data, function(x) sum(is.na(x))) 
```

**Observations**:

-   What are the basic facts about this dataset?
-   It has 3,416,238 rows and 24 columns.
-   There are many NA for contraband\_\* and reason_for_stop columns.
-   There are not less than 10 unique values for most of the columns, with the exception of subject_age, vehicle_registration_state (which has 52, 2 more than the 50 states), data, location, county_name, and raw_row_number.

Note that we have both a `subject_race` and `race_Raw` column. There are a few possibilities as to what `race_Raw` represents:

-   `race_Raw` could be the race of the police officer in the stop
-   `race_Raw` could be an unprocessed version of `subject_race`

Let's try to distinguish between these two possibilities.

### **q3** Check the set of factor levels for `subject_race` and `raw_Race`. What do you note about overlap / difference between the two sets?

```{r q3-task}
## TODO: Determine the factor levels for subject_race and raw_Race
subject_race <- df_data %>% pull(subject_race)
raw_race <- df_data %>% pull(raw_Race)

df_data %>% 
  distinct(subject_race)

df_data %>% 
  distinct(raw_Race)
```

**Observations**:

-   What are the unique values for `subject_race`?

-   white, hispanic, black, asian/pacific islander, other, unknown, NA

-   What are the unique values for `raw_Race`?

-   White, Hispanic, Black, Asian or Pacific Islander , Middle Eastern or East Indian (South Asian), American Indian or Alaskan Native, None - for no operator present citations only , A, NA

-   What is the overlap between the two sets?

-   If we ignore punctuation, the overlap is that both have white, hispanic, black, asian or pacific islander, and NA.

-   What is the difference between the two sets?

-   There are differences in punctuation, grouping, and capitalisation. `raw_Race` also has a category called A, which can be attributed to misprint. Middle Eastern or East Indian (South Asian) is not present in `subject_race`, and `raw_Race` has a category for American Indian or Alaskan Native, which is not present in `subject_race`.

### **q4** Check whether `subject_race` and `raw_Race` match for a large fraction of cases. Which of the two hypotheses above is most likely, based on your results?

*Note*: Just to be clear, I'm *not* asking you to do a *statistical* hypothesis test.

```{r q4-task}
## TODO: Devise your own way to test the hypothesis posed above.

df_race_compare <- df_data %>%
  mutate(
    # Standardize subject_race (already fairly clean)
    subject_race_clean = tolower(as.character(subject_race)),
    
    # Clean raw_Race to match subject_race categories
    raw_race_clean = case_when(
      str_to_lower(raw_Race) == "white" ~ "white",
      str_to_lower(raw_Race) == "hispanic" ~ "hispanic",
      str_to_lower(raw_Race) == "black" ~ "black",
      str_to_lower(raw_Race) == "asian or pacific islander" ~ "asian/pacific islander",
      str_to_lower(raw_Race) == "middle eastern or east indian (south asian)" ~ "other",
      str_to_lower(raw_Race) == "american indian or alaskan native" ~ "other",
      str_to_lower(raw_Race) == "none - for no operator present citations only" ~ "unknown",
      str_to_lower(raw_Race) == "a" ~ NA_character_,
      is.na(raw_Race) ~ NA_character_,
      TRUE ~ "other"  # Catch-all for remaining cases
    )
  ) %>%
  # Remove rows where either race value is missing
  filter(!is.na(subject_race_clean), !is.na(raw_race_clean))

# Calculate overall match rate
match_results <- df_race_compare %>%
  summarise(
    total_comparisons = n(),
    matches = sum(subject_race_clean == raw_race_clean),
    match_rate = matches / total_comparisons
  )

match_results
```

**Observations**

Between the two hypotheses:

-   `race_Raw` could be the race of the police officer in the stop
-   `race_Raw` could be an unprocessed version of `subject_race`

which is most plausible, based on your results?

-   There is a very high matching rate (98.1%). Unless officers are disproportionately likely to pull over people of their race, `race_Raw` is most likely an unprocessed version of `subject_race`.

## Vis

<!-- ------------------------- -->

### **q5** Compare the *arrest rate*---the fraction of total cases in which the subject was arrested---across different factors. Create as many visuals (or tables) as you need, but make sure to check the trends across all of the `subject` variables. Answer the questions under *observations* below.

(Note: Create as many chunks and visuals as you need)

```{r}
# arrest_rate vs subject_age

df_data %>%
  filter(!is.na(arrest_made)) %>%
  group_by(subject_age) %>%
  summarise(
    arrest_rate = mean(arrest_made, na.rm = TRUE)
  ) %>%
  ggplot(aes(x = subject_age, y = arrest_rate)) +
  geom_smooth(method = "lm", se = FALSE, color = "red", linetype = "dashed") +
  geom_point() +
  labs(title = "Arrest Rate vs Subject Age", x = "Subject Age", y = "Arrest Rate") +
  theme_minimal()
```

```{r}
# bar chart of arrest_rate vs subject_sex

df_data %>%
  filter(!is.na(arrest_made)) %>%
  group_by(subject_sex) %>%
  summarise(
    arrest_rate = mean(arrest_made, na.rm = TRUE)
  ) %>% 
  ggplot(aes(x = subject_sex, y = arrest_rate, fill = subject_sex)) +
  geom_bar(stat = "identity") +
  labs(title = "Arrest Rate vs Subject Sex", x = "Subject Sex", y = "Arrest Rate") +
  theme_minimal()

```

```{r}
# bar chart of arrest_rate vs subject_sex

df_data %>%
  filter(!is.na(arrest_made)) %>%
  group_by(subject_race) %>%
  summarise(
    arrest_rate = mean(arrest_made, na.rm = TRUE)
  ) %>% 
  ggplot(aes(x = reorder(subject_race, arrest_rate, decreasing=TRUE), y = arrest_rate, fill = subject_race)) +
  geom_bar(stat = "identity") +
  labs(title = "Arrest Rate vs Subject Race", x = "Subject Race", y = "Arrest Rate") +
  theme_minimal()
```

**Observations**:

-   How does `arrest_rate` tend to vary with `subject_age`?
    -   There is an overall decreasing relationship for age vs arrest rate. However, there is a spike in the front and in the very end. 
-   How does `arrest_rate` tend to vary with `subject_sex`?
    -   Male are disproportionately more likely to be arrested compared to females, at over 3% for males and 1.5% for females.
-   How does `arrest_rate` tend to vary with `subject_race`?
    -   Race is highly correlated with with arrest rates, with hispanic people getting arrested at almost 60% and black people getting arrested at over 30% being highest. Out of all the known races, asian/pacific islander is the least arrested.

# Modeling

<!-- -------------------------------------------------- -->

We're going to use a model to study the relationship between `subject` factors and arrest rate, but first we need to understand a bit more about *dummy variables*

### **q6** Run the following code and interpret the regression coefficients. Answer the the questions under *observations* below.

```{r q6-task}
## NOTE: No need to edit; inspect the estimated model terms.
fit_q6 <-
  glm(
    formula = arrest_made ~ subject_age + subject_race + subject_sex,
    data = df_data %>%
      filter(
        !is.na(arrest_made),
        subject_race %in% c("white", "black", "hispanic")
      ),
    family = "binomial"
  )

fit_q6 %>% tidy()
```

**Observations**:

-   Which `subject_race` levels are included in fitting the model?
    -   “white,” “black,” and “hispanic.”
-   Which `subject_race` levels have terms in the model?
    -   “Hispanic” and “white”. "black" is a reference category and not in the model.

You should find that each factor in the model has a level *missing* in its set of terms. This is because R represents factors against a *reference level*: The model treats one factor level as "default", and each factor model term represents a change from that "default" behavior. For instance, the model above treats `subject_sex==male` as the reference level, so the `subject_sexfemale` term represents the *change in probability* of arrest due to a person being female (rather than male).

The this reference level approach to coding factors is necessary for [technical reasons](https://www.andrew.cmu.edu/user/achoulde/94842/lectures/lecture10/lecture10-94842.html#why-is-one-of-the-levels-missing-in-the-regression), but it complicates interpreting the model results. For instance; if we want to compare two levels, neither of which are the reference level, we have to consider the difference in their model coefficients. But if we want to compare all levels against one "baseline" level, then we can relevel the data to facilitate this comparison.

By default `glm` uses the first factor level present as the reference level. Therefore we can use `mutate(factor = fct_relevel(factor, "desired_level"))` to set our `"desired_level"` as the reference factor.

### **q7** Re-fit the logistic regression from q6 setting `"white"` as the reference level for `subject_race`. Interpret the the model terms and answer the questions below.

```{r q7-task}
## TODO: Re-fit the logistic regression, but set "white" as the reference
## level for subject_race

df_q7 <- df_data %>%
  filter(
    !is.na(arrest_made),
    subject_race %in% c("white", "black", "hispanic")
  ) %>%
  mutate(subject_race = relevel(factor(subject_race), ref = "white"))

fit_q7 <-
  glm(
    formula = arrest_made ~ subject_age + subject_race + subject_sex,
    data = df_q7 %>%
      filter(
        !is.na(arrest_made),
        subject_race %in% c("white", "black", "hispanic")
      ),
    family = "binomial"
  )

fit_q7 %>% tidy()
```

**Observations**:

-   Which `subject_race` level has the highest probability of being arrested, according to this model? Which has the lowest probability?
    -   `Hispanic` has a highest probability, and `white` has the lowest probability.
-   What could explain this difference in probabilities of arrest across race? List **multiple** possibilities.
    -   Implicit/explicit bias of the police officer.
    -   Overpolicing of certain communities.
    -   Specific successful large-scale police operations that skewed the data.
-   Look at the set of variables in the dataset; do any of the columns relate to a potential explanation you listed?
    -   No.

One way we can explain differential arrest rates is to include some measure indicating the presence of an arrestable offense. We'll do this in a particular way in the next task.

### **q8** Re-fit the model using a factor indicating the presence of contraband in the subject's vehicle. Answer the questions under *observations* below.

```{r q8-task}
## TODO: Repeat the modeling above, but control for whether contraband was found
## during the police stop

fit_q8 <- glm(
  arrest_made ~ subject_age + subject_race + subject_sex + contraband_found,
  data = df_q7,
  family = "binomial"
)

fit_q8 %>% tidy()
```

**Observations**:

-   How does controlling for found contraband affect the `subject_race` terms in the model?
    -   When only looking at subject_race, `white` is least likely to be arrested. However, when controlling for contraband found, `black` is less likely to be arrested than `white`. Morever, `hispanic` arrested rate is reduced from 89% to 22%.

-   What does the *finding of contraband* tell us about the stop? What does it *not* tell us about the stop?
    -   It tells us that the car was searched. However, it does not tell us why it was searched, or whether the search was justified.

### **q9** Go deeper: Pose at least one more question about the data and fit at least one more model in support of answering that question.

Question

Do out of state plates invite more searches?

```{r}
# First, create a variable for out-of-state plates
df_q9 <- df_data %>%
  mutate(
    out_of_state = vehicle_registration_state != "MA",
    out_of_state = factor(out_of_state, labels = c("MA", "Out-of-State"))
  ) %>%
  filter(!is.na(out_of_state), !is.na(search_conducted))

# Model 1: Simple relationship between plates and searches
fit_q9_simple <- glm(
  search_conducted ~ out_of_state,
  data = df_q9,
  family = "binomial"
)

# Model 2: Controlling for other factors
fit_q9_controlled <- glm(
  search_conducted ~ out_of_state + subject_race + subject_sex + subject_age,
  data = df_q9,
  family = "binomial"
)

fit_q9_simple %>% tidy
fit_q9_controlled %>% tidy()
```

**Observations**:

-   According to the simple model, out of state plates are less likely to be searched. This could mean two things:
      1. Out of state plates are less likely to be searched.
      2. Out of state paltes are pulled over for less important reasons, and therefore less likely to be searched.
    When controlling for other factors, out of state plates still less likely to be searched, but at a smaller magnitude than the simple model. 

## Further Reading

<!-- -------------------------------------------------- -->

-   Stanford Open Policing Project [findings](https://openpolicing.stanford.edu/findings/).
